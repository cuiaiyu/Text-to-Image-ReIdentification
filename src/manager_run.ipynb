{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.wider_global_dataset_new import build_wider_dataloader\n",
    "from datasets.text_test_datasets import build_text_test_loader\n",
    "from datasets.image_test_datasets import build_image_test_loader\n",
    "from models.encoder import Model, MLP\n",
    "from evaluators.global_evaluator import GlobalEvaluator\n",
    "from evaluators.np_evaluator import NPEvaluator\n",
    "from loss.loss import crossmodal_triplet_loss, cos_distance, triplet_cos_loss\n",
    "from loggers.logger import Logger\n",
    "from manager import build_graph_optimizer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "from attentions.rga_attention import RGA_attend_one_to_many_batch, RGA_attend_one_to_many\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from configs.args import load_arg_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug\n"
     ]
    }
   ],
   "source": [
    "parser = load_arg_parser()\n",
    "cfg = parser.parse_args(\"\")\n",
    "cfg.data_root = \"/data/aiyucui2/wider\"\n",
    "root = cfg.data_root\n",
    "\n",
    "# data path\n",
    "cfg.anno_path = os.path.join(root, cfg.anno_path)\n",
    "cfg.img_dir = os.path.join(root, cfg.img_dir)\n",
    "cfg.val_anno_path = os.path.join(root, cfg.val_anno_path)\n",
    "cfg.val_img_dir = os.path.join(root, cfg.val_img_dir)\n",
    "cfg.gt_file_fn = os.path.join(root, cfg.gt_file_fn)\n",
    "\n",
    "# meta data path\n",
    "cfg.cheap_candidate_fn = os.path.join(root, cfg.cheap_candidate_fn)\n",
    "cfg.vocab_path = os.path.join(root, cfg.vocab_path)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "# sys path\n",
    "cfg.model_path = os.path.join(root, cfg.model_path)\n",
    "cfg.output_path = os.path.join(root, cfg.output_path)\n",
    "ckpt_root = \"/shared/rsaas/aiyucui2/wider_person/checkpoints/reID/baseline\"\n",
    "load_exp_name = \"dist_fn_cosine_imgbb_resnet50_capbb_bigru_embed_size_1024_batch_96_lr_0.0001_captype_sent_img_meltlayer_8_cos_margin_0.2_np_True\"\n",
    "cfg.load_ckpt_fn = os.path.join(ckpt_root, load_exp_name, \"stage_2_id_match_last.pt\")\n",
    "cfg.debug = False\n",
    "cfg.embed_size = 1024\n",
    "cfg.batch_size = 96\n",
    "cfg.img_backbone_opt = \"resnet50\"\n",
    "cfg.num_gpus = 1\n",
    "cfg.cap_backbone_opt = \"bigru\"\n",
    "cfg.dim = (384,128)\n",
    "cfg.dist_fn_opt = \"cosine\"\n",
    "cfg.np = True\n",
    "cfg.img_num_cut = 6\n",
    "cfg.img_num_cut = 1 if not cfg.np else cfg.img_num_cut\n",
    "\n",
    "cfg.cap_embed_type='sent'\n",
    "# exp_name\n",
    "cfg.exp_name = 'debug'\n",
    "cfg.model_path = os.path.join(\"/shared/rsaas/aiyucui2/wider_person\", cfg.model_path, cfg.exp_name)\n",
    "cfg.output_path = os.path.join(\"/shared/rsaas/aiyucui2/wider_person\", cfg.output_path, cfg.exp_name)\n",
    "\n",
    "if not os.path.exists(cfg.model_path):\n",
    "    os.mkdir(cfg.model_path)\n",
    "if not os.path.exists(cfg.output_path):\n",
    "    os.mkdir(cfg.output_path)\n",
    "# logger\n",
    "logger = Logger(\"test.txt\") #os.path.join(cfg.output_path, cfg.exp_name+\".txt\"))\n",
    "print(cfg.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     22,
     31,
     46,
     66
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ds] load annotations from /data/aiyucui2/wider/wider/train/train_anns_train.json\n",
      "size of dataset: 74264\n"
     ]
    }
   ],
   "source": [
    "# train loader\n",
    "train_loader = build_wider_dataloader(cfg)\n",
    "# test loader (loading image and text separately)\n",
    "test_text_loader = build_text_test_loader(cfg) \n",
    "test_image_loader = build_image_test_loader(cfg) \n",
    "\n",
    "# Evaluator\n",
    "Evaluator = NPEvaluator if cfg.np else GlobalEvaluator\n",
    "\n",
    "evaluator = Evaluator(img_loader=test_image_loader, \n",
    "                          cap_loader=test_text_loader, \n",
    "                          gt_file_path=cfg.gt_file_fn,\n",
    "                          embed_size=cfg.embed_size,\n",
    "                          logger=logger,\n",
    "                          dist_fn_opt=\"euclidean\")\n",
    "cos_evaluator = Evaluator(img_loader=test_image_loader, \n",
    "                          cap_loader=test_text_loader, \n",
    "                          gt_file_path=cfg.gt_file_fn,\n",
    "                          embed_size=cfg.embed_size,\n",
    "                          logger=logger,\n",
    "                          dist_fn_opt=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ckpt_path = \"/shared/rsaas/aiyucui2/wider_person/checkpoints/reID/resnet18_bigru_512/resnet18_bigru_512_id_initalized.pt\"\n",
    "#ckpt = torch.load(ckpt_path)\n",
    "cfg.num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     13,
     27,
     117
    ]
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import os\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from models.encoder import Model, MLP\n",
    "from loss.loss import triplet_cos_loss, crossmodal_triplet_loss\n",
    "\n",
    "from attentions.rga_attention import RGA_attend_one_to_many_batch, RGA_attend_one_to_many\n",
    "\n",
    "        \n",
    "def regional_alignment_text(fulls, parts, p2fs, dist_fn_opt):\n",
    "    start_index = 0\n",
    "    aligned = []\n",
    "    for i, jump in enumerate(p2fs):\n",
    "        curr_parts = parts[start_index:start_index + jump]\n",
    "        start_index += jump\n",
    "        curr_full = fulls[i:i+1]\n",
    "        aligned.append(RGA_attend_one_to_many(curr_full, curr_parts, dist_fn_opt))\n",
    "    return torch.cat(aligned)\n",
    "\n",
    "def regional_alignment_image(fulls, parts, dist_fn_opt):\n",
    "    return RGA_attend_one_to_many_batch(fulls, parts, dist_fn_opt)\n",
    "  \n",
    "    \n",
    "class Manager:\n",
    "    def __init__(self, args, logger):\n",
    "        self.log = logger.log\n",
    "        self.cfg = args\n",
    "        self._init_models()\n",
    "        self._init_criterion()\n",
    "    \n",
    "    def _init_criterion(self):\n",
    "        if self.cfg.dist_fn_opt == \"cosine\":\n",
    "            self.triplet_loss = triplet_cos_loss\n",
    "        elif self.cfg.dist_fn_opt == \"euclidean\":\n",
    "            self.triplet_loss = nn.TripletMarginLoss()\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.log(\"[Trainer][init] criterion initialized.\")\n",
    "\n",
    "    def _init_models(self):\n",
    "        # encoder\n",
    "        self.model = Model(embed_size=self.cfg.embed_size, \n",
    "                          image_opt=self.cfg.img_backbone_opt, \n",
    "                          caption_opt=self.cfg.cap_backbone_opt,\n",
    "                          cap_embed_type=self.cfg.cap_embed_type,\n",
    "                          img_num_cut=self.cfg.img_num_cut,\n",
    "                          regional_embed_size=self.cfg.regional_embed_size).cuda()\n",
    "        # id classifer\n",
    "        self.id_cls = nn.Linear(self.cfg.embed_size, self.cfg.num_ids).cuda()\n",
    "        # RGA image mlp\n",
    "        self.rga_img_mlp = MLP(self.cfg.regional_embed_size, self.cfg.embed_size).cuda()\n",
    "        # RGA text mlp\n",
    "        self.rga_cap_mlp = MLP(self.cfg.embed_size, self.cfg.embed_size).cuda()\n",
    "        # gpu\n",
    "        self.all_models = {\n",
    "            \"model\": self.model,\n",
    "            \"id_cls\": self.id_cls, \n",
    "            \"rga_img_mlp\": self.rga_img_mlp,\n",
    "            \"rga_cap_mlp\": self.rga_cap_mlp,\n",
    "        }\n",
    "        print(self.cfg.num_gpus)\n",
    "        if self.cfg.num_gpus > 1:\n",
    "            print('here')\n",
    "            for name in self.all_models.keys():\n",
    "                print('data parallel')\n",
    "                self.all_models[name] = nn.DataParallel(self.all_models[name])\n",
    "        # load ckpt\n",
    "        self.reset_ckpt()\n",
    "        \n",
    "        \n",
    "        self.log(\"[Trainer][init] model initialized.\")\n",
    "\n",
    "    def reset_ckpt(self):\n",
    "        self.start_epoch = 0\n",
    "        self.acc_history = []\n",
    "        self.best_acc = ({'top-1':0, 'top-1': 0, 'top-1': 0}, self.start_epoch)\n",
    "        if self.cfg.load_ckpt_fn == \"0\":\n",
    "            self.log(\"[Trainer][init] initialize fresh model.\")\n",
    "            return\n",
    "        ckpt = torch.load(self.cfg.load_ckpt_fn)\n",
    "        self.start_epoch = ckpt[\"epoch\"] + 1\n",
    "        self.acc_history = ckpt[\"acc_history\"]\n",
    "        for name, network in self.all_models.items():\n",
    "            if name in ckpt:\n",
    "                network.load_state_dict(ckpt[name], strict=False)\n",
    "                self.log(\"[Trainer][init] load pre-trained %s from %s.\" % (name, self.cfg.load_ckpt_fn))\n",
    "\n",
    "              \n",
    "    def save_ckpt(self, epoch, acc, fn):\n",
    "        # update acc history \n",
    "        self.acc_history.append((acc, epoch))\n",
    "        if acc['top-1'] > self.best_acc[0]['top-1']:\n",
    "            self.best_acc = (acc, epoch)\n",
    "        # ckpt \n",
    "        ckpt = {\n",
    "            \"epoch\": epoch,\n",
    "            \"acc_history\": self.acc_history,\n",
    "            \"best_acc\": self.best_acc,\n",
    "            }\n",
    "        for name, network in self.all_models.items():\n",
    "            ckpt[name] = network.module.state_dict() if isinstance(network, nn.DataParallel) else network.state_dict()\n",
    "\n",
    "        path = os.path.join(self.cfg.model_path, fn)\n",
    "        torch.save(ckpt, path)\n",
    "            \n",
    "    def todevice(self, batch):\n",
    "        ret = []\n",
    "        for arg in batch:\n",
    "            if isinstance(arg, torch.Tensor):\n",
    "                arg = arg.cuda()\n",
    "            ret.append(arg)\n",
    "        return tuple(ret)\n",
    "    \n",
    "    def melt_img_layer(self, num_layer_to_melt=1):\n",
    "        if isinstance(self.model, nn.DataParallel):\n",
    "            self.model.module.img_backbone.melt_layer(8 - num_layer_to_melt)\n",
    "        else:\n",
    "            self.model.img_backbone.melt_layer(8 - num_layer_to_melt)\n",
    "     \n",
    "    def train_epoch_global(self, train_data, optimizer, epoch, note=\"train\"):\n",
    "        self.model.train()\n",
    "        cum_tri_loss, cum_id_loss = 0.0, 0.0\n",
    "        for i, data in tqdm(enumerate(train_data), \"%s, epoch%d\" % (note, epoch)):\n",
    "            # load data\n",
    "            data = self.todevice(data)\n",
    "            img, cap, pid = data\n",
    "            \n",
    "            # encode\n",
    "            #img, pos_img, neg_img = self.model(img), self.model(pos_img), self.model(neg_img)\n",
    "            #cap, pos_cap, neg_cap = self.model(cap), self.model(pos_cap), self.model(neg_cap)\n",
    "            img, cap = self.model(img), self.model(cap)\n",
    "\n",
    "\n",
    "            # loss\n",
    "            tri_loss = triplet_cos_loss(img, cap, pid)\n",
    "            id_loss = self.cls_loss(self.id_cls(img), pid) + self.cls_loss(self.id_cls(cap), pid)\n",
    "            loss = tri_loss + id_loss\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            # log\n",
    "            cum_tri_loss += tri_loss.item()\n",
    "            cum_id_loss += id_loss.item()\n",
    "            if (i+1) % self.cfg.print_freq == 0:\n",
    "                out_string = \"[ep-%d, bs-%d] \" % (epoch, i)\n",
    "                out_string += \"[tri-loss] %.6f, \" % (cum_tri_loss / self.cfg.print_freq)\n",
    "                out_string += \"[id-loss] %.6f, \" % (cum_id_loss / self.cfg.print_freq)\n",
    "                self.log(out_string)\n",
    "                cum_tri_loss, cum_id_loss = 0.0, 0.0\n",
    "                \n",
    "    def train_epoch_regional(self, train_data, optimizer, epoch, note=\"train\"):\n",
    "        self.model.train(); self.rga_img_mlp.train(); self.rga_cap_mlp.train()\n",
    "\n",
    "        cum_tri_loss, cum_tri_image_regional_loss, cum_tri_text_regional_loss, cum_id_loss = 0.0, 0.0, 0.0, 0.0\n",
    "        for i, data in tqdm(enumerate(train_data), \"%s, epoch%d\" % (note,epoch)):\n",
    "            # load data\n",
    "            data = self.todevice(data)\n",
    "            (img, pos_img, neg_img, \n",
    "             cap, pos_cap, neg_cap,\n",
    "             nps, pos_nps, neg_nps,\n",
    "             n2c, pos_n2c, neg_n2c,\n",
    "             pid, pos_pid, neg_pid) = data\n",
    "\n",
    "\n",
    "            img, img_part = self.model(img)\n",
    "            pos_img, pos_img_part = self.model(pos_img)\n",
    "            neg_img, neg_img_part = self.model(neg_img)\n",
    "            cap, pos_cap, neg_cap = self.model(cap), self.model(pos_cap), self.model(neg_cap)\n",
    "            \n",
    "            # N, M, T = nps.size()\n",
    "            nps = self.rga_cap_mlp(self.model(nps))\n",
    "            pos_nps = self.rga_cap_mlp(self.model(pos_nps))\n",
    "            neg_nps = self.rga_cap_mlp(self.model(neg_nps))\n",
    "            #nps = self.rga_cap_mlp(self.model(nps.reshape(-1, T))).reshape(N, M, -1)\n",
    "            #pos_nps = self.rga_cap_mlp(self.model(pos_nps.reshape(-1, T))).reshape(N, M, -1)\n",
    "            #neg_nps = self.rga_cap_mlp(self.model(neg_nps.reshape(-1, T))).reshape(N, M, -1)\n",
    "            \n",
    "            # part\n",
    "            img_part = self.rga_img_mlp(img_part)\n",
    "            pos_img_part = self.rga_img_mlp(pos_img_part)\n",
    "            neg_img_part = self.rga_img_mlp(neg_img_part)\n",
    "\n",
    "            img_part = RGA_attend_one_to_many_batch(cap, img_part, self.cfg.dist_fn_opt)\n",
    "            pos_img_part = RGA_attend_one_to_many_batch(pos_cap, pos_img_part, self.cfg.dist_fn_opt)\n",
    "            neg_img_part = RGA_attend_one_to_many_batch(neg_cap, neg_img_part, self.cfg.dist_fn_opt)\n",
    "            cap_part = regional_alignment_text(img, nps, n2c, self.cfg.dist_fn_opt)\n",
    "            pos_cap_part = regional_alignment_text(pos_img, pos_nps, pos_n2c, self.cfg.dist_fn_opt)\n",
    "            neg_cap_part = regional_alignment_text(neg_img, neg_nps, neg_n2c, self.cfg.dist_fn_opt)\n",
    "            #cap_part = RGA_attend_one_to_many_batch(img, nps, self.cfg.dist_fn_opt)\n",
    "            #pos_cap_part = RGA_attend_one_to_many_batch(pos_img, pos_nps, self.cfg.dist_fn_opt)\n",
    "            #neg_cap_part = RGA_attend_one_to_many_batch(neg_img, neg_nps, self.cfg.dist_fn_opt)\n",
    "\n",
    "            # loss\n",
    "            tri_loss =  crossmodal_triplet_loss(img,pos_img,neg_img, \n",
    "                                                  cap, pos_cap, neg_cap, \n",
    "                                                  self.triplet_loss, self.cfg.dist_fn_opt) \n",
    "            tri_image_regional_loss =  crossmodal_triplet_loss(img_part,pos_img_part,neg_img_part, \n",
    "                                                  cap, pos_cap, neg_cap, \n",
    "                                                  self.triplet_loss, self.cfg.dist_fn_opt) \n",
    "            tri_text_regional_loss =  crossmodal_triplet_loss(img,pos_img,neg_img, \n",
    "                                                  cap_part, pos_cap_part, neg_cap_part, \n",
    "                                                  self.triplet_loss, self.cfg.dist_fn_opt) \n",
    "            id_loss = self.cls_loss(self.id_cls(img), pid) +  self.cls_loss(self.id_cls(cap), pid)\n",
    "\n",
    "\n",
    "            loss = tri_loss + tri_image_regional_loss  + tri_text_regional_loss + id_loss\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # log\n",
    "            cum_tri_loss += tri_loss.item()\n",
    "            cum_tri_image_regional_loss += tri_image_regional_loss.item()\n",
    "            cum_tri_text_regional_loss += tri_text_regional_loss.item()\n",
    "            cum_id_loss += id_loss.item()\n",
    "            \n",
    "            if (i+1) % self.cfg.print_freq == 0:\n",
    "                out_string = \"[ep-%d, bs-%d] \" % (epoch, i)\n",
    "                out_string += \"[id-loss] %.6f, \" % (cum_id_loss / self.cfg.print_freq)\n",
    "                out_string += \"[tri-loss] %.6f, \" % (cum_tri_loss / self.cfg.print_freq)\n",
    "                out_string += \"[img_rga] %.6f, \" %  (cum_tri_image_regional_loss / self.cfg.print_freq)\n",
    "                out_string += \"[cap_rga] %.6f \" % (cum_tri_text_regional_loss / self.cfg.print_freq)\n",
    "                self.log(out_string)\n",
    "                cum_tri_loss, cum_tri_image_regional_loss, cum_tri_text_regional_loss, cum_id_loss = 0.0, 0.0, 0.0, 0.0       \n",
    "    def train_epoch_id(self, train_data, optimizer, epoch, note=\"train\"):\n",
    "        self.model.train()\n",
    "        self.id_cls.train()\n",
    "        cum_loss = 0.0\n",
    "        for i, data in tqdm(enumerate(train_data), \"%s, epoch%d\" % (note,epoch)):\n",
    "            # load data\n",
    "            data = self.todevice(data)\n",
    "            (img, cap, pid) = data\n",
    "            img = self.model(img)\n",
    "            cap = self.model(cap)\n",
    "\n",
    "            # loss\n",
    "            loss = 0.0\n",
    "            loss = loss + self.cls_loss(self.id_cls(img), pid) +  self.cls_loss(self.id_cls(cap), pid)\n",
    "            cum_loss += loss.item()\n",
    "            \n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            # log\n",
    "            if (i+1) % self.cfg.print_freq == 0:\n",
    "                self.log(\"ep-%d, bs-%d, [id-loss] %.6f\" % (epoch, i, cum_loss / self.cfg.print_freq))\n",
    "                cum_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[Trainer][init] load pre-trained model from /shared/rsaas/aiyucui2/wider_person/checkpoints/reID/baseline/dist_fn_cosine_imgbb_resnet50_capbb_bigru_embed_size_1024_batch_96_lr_0.0001_captype_sent_img_meltlayer_8_cos_margin_0.2_np_True/stage_2_id_match_last.pt.\n",
      "[Trainer][init] load pre-trained id_cls from /shared/rsaas/aiyucui2/wider_person/checkpoints/reID/baseline/dist_fn_cosine_imgbb_resnet50_capbb_bigru_embed_size_1024_batch_96_lr_0.0001_captype_sent_img_meltlayer_8_cos_margin_0.2_np_True/stage_2_id_match_last.pt.\n",
      "[Trainer][init] load pre-trained rga_img_mlp from /shared/rsaas/aiyucui2/wider_person/checkpoints/reID/baseline/dist_fn_cosine_imgbb_resnet50_capbb_bigru_embed_size_1024_batch_96_lr_0.0001_captype_sent_img_meltlayer_8_cos_margin_0.2_np_True/stage_2_id_match_last.pt.\n",
      "[Trainer][init] load pre-trained rga_cap_mlp from /shared/rsaas/aiyucui2/wider_person/checkpoints/reID/baseline/dist_fn_cosine_imgbb_resnet50_capbb_bigru_embed_size_1024_batch_96_lr_0.0001_captype_sent_img_meltlayer_8_cos_margin_0.2_np_True/stage_2_id_match_last.pt.\n",
      "[Trainer][init] model initialized.\n",
      "[Trainer][init] criterion initialized.\n"
     ]
    }
   ],
   "source": [
    "cfg.num_ids = len(train_loader.dataset.person2label.values())\n",
    "manager = Manager(cfg, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build db global imgs: 33it [00:05,  6.68it/s]\n",
      "build db global caps: 65it [00:03, 22.53it/s]\n",
      "scoremat_rga_img: 100%|██████████| 6156/6156 [00:14<00:00, 414.40it/s]\n",
      "scoremat_rga_cap(nps): 6156it [00:21, 281.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[global] R@1: 0.4252 | R@5: 0.6731 | R@10: 0.7684\n",
      "[img_rga] R@1: 0.3803 | R@5: 0.6226 | R@10: 0.7232\n",
      "[cap_rga] R@1: 0.2856 | R@5: 0.5166 | R@10: 0.6275\n",
      "[fusion] R@1: 0.4359 | R@5: 0.6711 | R@10: 0.7694\n",
      "[cosine   ][global] R@1: 0.4359 | R@5: 0.6711 | R@10: 0.7694\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    if cfg.np:\n",
    "        acc = cos_evaluator.evaluate(manager.model, manager.rga_img_mlp, manager.rga_cap_mlp)\n",
    "    else:\n",
    "        acc = cos_evaluator.evaluate(manager.model)\n",
    "    logger.log('[cosine   ][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (acc['top-1'], acc['top-5'], acc['top-10']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: ID Loss only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    logger.log(\"======== [Stage 1] ============\")\n",
    "    manager.melt_img_layer(num_layer_to_melt=1)\n",
    "    param_to_optimize = build_graph_optimizer([manager.model, manager.id_cls])\n",
    "    optimizer = optim.Adam(param_to_optimize, lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10)\n",
    "    \n",
    "    for epoch in range(0):\n",
    "        manager.train_epoch_id(train_loader, optimizer, epoch, \"train-stage-1\")\n",
    "        acc = evaluator.evaluate(manager.model)\n",
    "        logger.log('[euclidean][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (acc['top-1'], acc['top-5'], acc['top-10']))\n",
    "        acc = cos_evaluator.evaluate(manager.model)\n",
    "        logger.log('[cosine   ][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (acc['top-1'], acc['top-5'], acc['top-10']))\n",
    "        scheduler.step()\n",
    "        manager.save_ckpt(epoch, acc, 'stage_1_id_last.pt')\n",
    "    manager.save_ckpt(epoch, acc, 'id_initialized.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Matching + ID Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32ba209271340d192e4d5c0f9a9c15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train-stage-2, epoch0', max=1, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 15, got 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f585e362eca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch_regional\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch_global\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train-stage-2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrga_img_mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrga_cap_mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-41c76e5b71b0>\u001b[0m in \u001b[0;36mtrain_epoch_regional\u001b[0;34m(self, train_data, optimizer, epoch, note)\u001b[0m\n\u001b[1;32m    163\u001b[0m              \u001b[0mnps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_nps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_nps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m              \u001b[0mn2c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_n2c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_n2c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m              pid, pos_pid, neg_pid) = data\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 15, got 5)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "manager.melt_img_layer(num_layer_to_melt=8)\n",
    "param_to_optimize = build_graph_optimizer([manager.model, manager.id_cls])\n",
    "optimizer = optim.Adam(param_to_optimize, lr=2e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5)\n",
    "train_epoch = manager.train_epoch_regional if cfg.np else manager.train_epoch_global\n",
    "for epoch in range(40):\n",
    "    train_epoch(train_loader, optimizer, epoch, \"train-stage-2\")\n",
    "    if cfg.np:\n",
    "        acc = evaluator.evaluate(manager.model, manager.rga_img_mlp, manager.rga_cap_mlp)\n",
    "        cos_acc = cos_evaluator.evaluate(manager.model, manager.rga_img_mlp, manager.rga_cap_mlp)\n",
    "    else:\n",
    "        acc = evaluator.evaluate(manager.model)\n",
    "        cos_acc = cos_evaluator.evaluate(manager.model)\n",
    "    logger.log('[euclidean][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (acc['top-1'], acc['top-5'], acc['top-10']))\n",
    "    logger.log('[cosine   ][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (cos_acc['top-1'], cos_acc['top-5'], cos_acc['top-10']))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.save_ckpt(epoch, acc, \"match_stage2_trained.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
