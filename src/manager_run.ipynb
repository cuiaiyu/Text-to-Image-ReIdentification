{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.wider_global_dataset import build_wider_dataloader\n",
    "from datasets.text_test_datasets import build_text_test_loader\n",
    "from datasets.image_test_datasets import build_image_test_loader\n",
    "from models.encoder import Model, MLP\n",
    "from evaluators.global_evaluator import GlobalEvaluator\n",
    "from loss.loss import crossmodal_triplet_loss, cos_distance\n",
    "from loggers.logger import Logger\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from configs.args import load_arg_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = load_arg_parser()\n",
    "cfg = parser.parse_args(\"\")\n",
    "cfg.data_root = \"/data/aiyucui2/wider\"\n",
    "root = cfg.data_root\n",
    "\n",
    "# data path\n",
    "cfg.anno_path = os.path.join(root, cfg.anno_path)\n",
    "cfg.img_dir = os.path.join(root, cfg.img_dir)\n",
    "cfg.val_anno_path = os.path.join(root, cfg.val_anno_path)\n",
    "cfg.val_img_dir = os.path.join(root, cfg.val_img_dir)\n",
    "cfg.gt_file_fn = os.path.join(root, cfg.gt_file_fn)\n",
    "\n",
    "# meta data path\n",
    "cfg.cheap_candidate_fn = os.path.join(root, cfg.cheap_candidate_fn)\n",
    "cfg.vocab_path = os.path.join(root, cfg.vocab_path)\n",
    "\n",
    "# sys path\n",
    "cfg.model_path = os.path.join(root, cfg.model_path)\n",
    "cfg.output_path = os.path.join(root, cfg.output_path)\n",
    "ckpt_root = \"/shared/rsaas/aiyucui2/wider_person/checkpoints/reID\"\n",
    "load_exp_name = \"dist_fn_cosine_imgbb_resnet18_capbb_bigru_embed_size_512_batch_96_lr_0.0001_captype_sent_img_meltlayer_8\"\n",
    "cfg.load_ckpt_fn = '0' #os.path.join(ckpt_root, load_exp_name, \"stage1.pt\")\n",
    "cfg.debug = False\n",
    "cfg.embed_size = 512\n",
    "cfg.batch_size = 96\n",
    "cfg.img_backbone_opt = \"resnet18\"\n",
    "cfg.cap_backbone_opt = \"bigru\"\n",
    "cfg.dim = (384,128)\n",
    "cfg.dist_fn_opt = \"cosine\"\n",
    "cfg.np = False\n",
    "cfg.img_num_cut = 6\n",
    "cfg.img_num_cut = 1 if not cfg.np else cfg.img_num_cut\n",
    "cfg.cap_embed_type='sent'\n",
    "# exp_name\n",
    "exp_name = \"dist_fn_{}_imgbb_{}_capbb_{}_embed_size_{}_batch_{}_lr_{}_captype_{}\".format(cfg.dist_fn_opt,\n",
    "                                                                       cfg.img_backbone_opt,\n",
    "                                                                       cfg.cap_backbone_opt,\n",
    "                                                                       cfg.embed_size,\n",
    "                                                                       cfg.batch_size,\n",
    "                                                                       cfg.lr,\n",
    "                                                                                         cfg.cap_embed_type)\n",
    "# logger\n",
    "logger = Logger(\"test.txt\") #os.path.join(cfg.output_path, cfg.exp_name+\".txt\"))\n",
    "print(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loader\n",
    "train_loader = build_wider_dataloader(cfg)\n",
    "\n",
    "# test loader (loading image and text separately)\n",
    "test_text_loader = build_text_test_loader(cfg) \n",
    "test_image_loader = build_image_test_loader(cfg) \n",
    "\n",
    "# Evaluator\n",
    "Evaluator = NPEvaluator if cfg.np else GlobalEvaluator\n",
    "\n",
    "evaluator = Evaluator(img_loader=test_image_loader, \n",
    "                          cap_loader=test_text_loader, \n",
    "                          gt_file_path=cfg.gt_file_fn,\n",
    "                          embed_size=cfg.embed_size,\n",
    "                          logger=logger,\n",
    "                          dist_fn_opt=\"euclidean\")\n",
    "cos_evaluator = Evaluator(img_loader=test_image_loader, \n",
    "                          cap_loader=test_text_loader, \n",
    "                          gt_file_path=cfg.gt_file_fn,\n",
    "                          embed_size=cfg.embed_size,\n",
    "                          logger=logger,\n",
    "                          dist_fn_opt=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     85,
     93,
     99,
     130,
     207
    ]
   },
   "outputs": [],
   "source": [
    "def regional_alignment_text(fulls, parts, p2fs, dist_fn_opt):\n",
    "    start_index = 0\n",
    "    aligned = []\n",
    "    for i, jump in enumerate(p2fs):\n",
    "        curr_parts = parts[start_index:start_index + jump]\n",
    "        start_index += jump\n",
    "        curr_full = fulls[i:i+1]\n",
    "        aligned.append(RGA_attend_one_to_many(curr_full, curr_parts, dist_fn_opt))\n",
    "    return torch.cat(aligned)\n",
    "\n",
    "def regional_alignment_image(fulls, parts, dist_fn_opt):\n",
    "    return RGA_attend_one_to_many_batch(fulls, parts, dist_fn_opt)\n",
    "  \n",
    "    \n",
    "class Manager:\n",
    "    def __init__(self, args, logger):\n",
    "        self.cfg = args\n",
    "        self._init_models()\n",
    "        self._init_criterion()\n",
    "        self.log = logger.log\n",
    "    \n",
    "    def _init_criterion(self):\n",
    "        if self.cfg.dist_fn_opt == \"cosine\":\n",
    "            self.triplet_loss = triplet_cos_loss\n",
    "        elif self.cfg.dist_fn_opt == \"euclidean\":\n",
    "            self.triplet_loss = nn.TripletMarginLoss()\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.log(\"[Trainer][init] criterion initialized.\")\n",
    "\n",
    "    def _init_models(self):\n",
    "        self.model = Model(embed_size=self.cfg.embed_size, \n",
    "                          image_opt=self.cfg.img_backbone_opt, \n",
    "                          caption_opt=self.cfg.cap_backbone_opt,\n",
    "                          cap_embed_type=self.cfg.cap_embed_type,\n",
    "                          img_num_cut=self.cfg.img_num_cut,\n",
    "                          regional_embed_size=self.cfg.regional_embed_size).cuda()\n",
    "        self.id_cls = nn.Linear(cfg.embed_size, cfg.num_ids)\n",
    "        self.rga_img_mlp = MLP(self.cfg.regional_embed_size, self.cfg.embed_size).cuda()\n",
    "        self.rga_cap_mlp = MLP(self.cfg.embed_size, self.cfg.embed_size).cuda()\n",
    "        \n",
    "        # load ckpt\n",
    "        self.reset_ckpt()\n",
    "        \n",
    "        # gpu\n",
    "        self.all_models = {\n",
    "            \"model\": self.model,\n",
    "            \"id_cls\": self.id_cls, \n",
    "            \"rga_img_mlp\": self.rga_img_mlp,\n",
    "            \"rga_cap_mlp\": self.rga_cap_mlp,\n",
    "        }\n",
    "        self.log(\"[Trainer][init] model initialized.\")\n",
    "\n",
    "    def reset_ckpt(self):\n",
    "        self.start_epoch = 0\n",
    "        self.acc_history = []\n",
    "        self.best_acc = (0, self.start_epoch)\n",
    "        if cfg.load_ckpt_fn == \"0\":\n",
    "            self.log(\"[Trainer][init] initialize fresh model.\")\n",
    "            return\n",
    "        ckpt = torch.load(cfg.load_ckpt_fn)\n",
    "        self.start_epoch = ckpt[\"epoch\"] + 1\n",
    "        self.acc_history = ckpt[\"acc_history\"]\n",
    "        for name, network in self.all_models.items():\n",
    "            if name in ckpt:\n",
    "                network.load_state_dict(ckpt[name], False)\n",
    "                self.log(\"[Trainer][init] load pre-trained %s from %s.\" % (network, cfg.load_ckpt_fn))\n",
    "\n",
    "              \n",
    "    def save_ckpt(self, epoch, acc, fn):\n",
    "        # update acc history \n",
    "        self.acc_history.append((acc, epoch))\n",
    "        if acc[0] > self.best_acc[0]:\n",
    "            self.best_acc = (acc, epoch)\n",
    "        # ckpt \n",
    "        ckpt = {\n",
    "            \"epoch\": epoch,\n",
    "            \"acc_history\": self.acc_history,\n",
    "            \"best_acc\": self.best_acc,\n",
    "            }\n",
    "        for name, network in self.all_models.items():\n",
    "            ckpt[name] = network.module.state_dict() if isinstance(network, nn.DataParallel) else network.state_dict(),\n",
    "\n",
    "        path = os.path.join(self.cfg.model_path, fn)\n",
    "        torch.save(ckpt, path)\n",
    "            \n",
    "    def todevice(self, batch):\n",
    "        ret = []\n",
    "        for arg in batch:\n",
    "            if isinstance(arg, torch.Tensor):\n",
    "                arg = arg.cuda()\n",
    "            ret.append(arg)\n",
    "        return tuple(ret)\n",
    "    \n",
    "    def melt_img_layer(self, num_layer_to_melt=1):\n",
    "        if isinstance(model, nn.DataParallel):\n",
    "            self.model.module.img_backbone.melt_layer(8 - num_layer_to_melt)\n",
    "        else:\n",
    "            self.model.img_backbone.melt_layer(8 - num_layer_to_melt)\n",
    "     \n",
    "    def train_epoch_global(train_data, optimizer, epoch, note=\"train\"):\n",
    "        self.model.train()\n",
    "        cum_tri_loss, cum_id_loss = 0.0, 0.0\n",
    "        for i, data in tqdm(enumerate(train_data), \"%s, epoch%d\" % (note, epoch)):\n",
    "            # load data\n",
    "            data = self.todevice(data)\n",
    "            (img,pos_img,neg_img, cap, pos_cap, neg_cap, pid, pos_pid, neg_pid) = data\n",
    "            \n",
    "            # encode\n",
    "            img, pos_img, neg_img = self.model(img), self.model(pos_img), self.model(neg_img)\n",
    "            cap, pos_cap, neg_cap = self.model(cap), self.model(pos_cap), self.model(neg_cap)\n",
    "\n",
    "            # loss\n",
    "            tri_loss =  crossmodal_triplet_loss(img,pos_img,neg_img, \n",
    "                                                  cap, pos_cap, neg_cap, \n",
    "                                                  self.triplet_loss, self.cfg.dist_fn_opt)  \n",
    "            id_loss = self.cls_loss(self.id_cls(img), pid) +  self.cls_loss(self.id_cls(cap), pid)\n",
    "            loss = tri_loss + id_loss\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            # log\n",
    "            cum_tri_loss += tri_loss.item()\n",
    "            cum_id_loss += id_loss.item()\n",
    "            if (i+1) % self.cfg.print_freq == 0:\n",
    "                out_string = \"[ep-%d, bs-%d] \" % (epoch, i)\n",
    "                out_string += \"[tri-loss] %.6f, \" % cum_tri_loss / self.cfg.print_freq\n",
    "                out_string += \"[id-loss] %.6f, \" % (cum_id_loss / self.cfg.print_freq)\n",
    "                self.log(out_string)\n",
    "                cum_tri_loss, cum_id_loss = 0.0, 0.0\n",
    "                \n",
    "    def train_epoch_regional(train_data, optimizer, epoch, note=\"train\"):\n",
    "        self.model.train(); self.rga_img_mlp.train(); self.rga_cap_mlp.train()\n",
    "\n",
    "        cum_tri_loss, cum_tri_image_regional_loss, cum_tri_text_regional_loss, cum_id_loss = 0.0, 0.0, 0.0, 0.0\n",
    "        for i, data in tqdm(enumerate(train_data), \"%s, epoch%d\" % (note,epoch)):\n",
    "            # load data\n",
    "            data = self.todevice(data)\n",
    "            (img, pos_img, neg_img, \n",
    "             cap, pos_cap, neg_cap,\n",
    "             nps, pos_nps, neg_nps,\n",
    "             n2c, pos_n2c, neg_n2c,\n",
    "             pid, pos_pid, neg_pid) = data\n",
    "\n",
    "\n",
    "            img, img_part = self.model(img)\n",
    "            pos_img, pos_img_part = self.model(pos_img)\n",
    "            neg_img, neg_img_part = self.model(neg_img)\n",
    "            cap, pos_cap, neg_cap = self.model(cap), self.model(pos_cap), self.model(neg_cap)\n",
    "            \n",
    "            N, M, T = nps.size()\n",
    "            nps = self.rga_cap_mlp(self.model(nps.reshape(-1, T))).reshape(N, M, -1)\n",
    "            pos_nps = self.rga_cap_mlp(self.model(pos_nps.reshape(-1, T))).reshape(N, M, -1)\n",
    "            neg_nps = self.rga_cap_mlp(self.model(neg_nps.reshape(-1, T))).reshape(N, M, -1)\n",
    "            \n",
    "            # part\n",
    "            img_part = self.rga_img_mlp(img_part)\n",
    "            pos_img_part = self.rga_img_mlp(pos_img_part)\n",
    "            neg_img_part = self.rga_img_mlp(neg_img_part)\n",
    "\n",
    "            img_part = RGA_attend_one_to_many_batch(cap, img_part, self.cfg.dist_fn_opt)\n",
    "            pos_img_part = RGA_attend_one_to_many_batch(pos_cap, pos_img_part, self.cfg.dist_fn_opt)\n",
    "            neg_img_part = RGA_attend_one_to_many_batch(neg_cap, neg_img_part, self.cfg.dist_fn_opt)\n",
    "            #cap_part = regional_alignment_text(img, nps, n2c, cfg.dist_fn_opt)\n",
    "            #pos_cap_part = regional_alignment_text(pos_img, pos_nps, pos_n2c, cfg.dist_fn_opt)\n",
    "            #neg_cap_part = regional_alignment_text(neg_img, neg_nps, neg_n2c, cfg.dist_fn_opt)\n",
    "            cap_part = RGA_attend_one_to_many_batch(img, nps, self.cfg.dist_fn_opt)\n",
    "            pos_cap_part = RGA_attend_one_to_many_batch(pos_img, pos_nps, self.cfg.dist_fn_opt)\n",
    "            neg_cap_part = RGA_attend_one_to_many_batch(neg_img, neg_nps, self.cfg.dist_fn_opt)\n",
    "\n",
    "            # loss\n",
    "            tri_loss =  crossmodal_triplet_loss(img,pos_img,neg_img, \n",
    "                                                  cap, pos_cap, neg_cap, \n",
    "                                                  triplet_loss, self.cfg.dist_fn_opt) \n",
    "            tri_image_regional_loss =  crossmodal_triplet_loss(img_part,pos_img_part,neg_img_part, \n",
    "                                                  cap, pos_cap, neg_cap, \n",
    "                                                  triplet_loss, self.cfg.dist_fn_opt) \n",
    "            tri_text_regional_loss =  crossmodal_triplet_loss(img,pos_img,neg_img, \n",
    "                                                  cap_part, pos_cap_part, neg_cap_part, \n",
    "                                                  triplet_loss, self.cfg.dist_fn_opt) \n",
    "            id_loss = self.cls_loss(self.id_cls(img), pid) +  self.cls_loss(self.id_cls(cap), pid)\n",
    "\n",
    "\n",
    "            loss = tri_loss + tri_image_regional_loss  + tri_text_regional_loss + id_loss\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # log\n",
    "            cum_tri_loss += tri_loss.item()\n",
    "            cum_tri_image_regional_loss += tri_image_regional_loss.item()\n",
    "            cum_tri_text_regional_loss += tri_text_regional_loss.item()\n",
    "            cum_id_loss += id_loss.item()\n",
    "            \n",
    "            if (i+1) % self.cfg.print_freq == 0:\n",
    "                out_string = \"[ep-%d, bs-%d] \" % (epoch, i)\n",
    "                out_string += \"[id-loss] %.6f, \" % (cum_id_loss / self.cfg.print_freq)\n",
    "                out_string += \"[tri-loss] %.6f, \" % cum_tri_loss / self.cfg.print_freq\n",
    "                out_string += \"[img_rga] %.6f, \" %  cum_tri_image_regional_loss / self.cfg.print_freq\n",
    "                out_string += \"[cap_rga] %.6f \" % cum_tri_text_regional_loss / self.cfg.print_freq\n",
    "                self.log(out_string)\n",
    "                cum_tri_loss, cum_tri_image_regional_loss, cum_tri_text_regional_loss, cum_id_loss = 0.0, 0.0, 0.0, 0.0\n",
    "               \n",
    "            \n",
    "            \n",
    "    def train_epoch_id(train_data, optimizer, epoch, note=\"train\"):\n",
    "        model.train()\n",
    "        cum_loss = 0.0\n",
    "        for i, data in tqdm(enumerate(train_data), \"%s, epoch%d\" % (note,epoch)):\n",
    "            # load data\n",
    "            data = self.todevice(data)\n",
    "            (img,pos_img,neg_img, cap, pos_cap, neg_cap, pid, pos_pid, neg_pid) = data\n",
    "            img = model(img)\n",
    "            cap = model(cap)\n",
    "\n",
    "            # loss\n",
    "            loss = 0.0\n",
    "            loss = loss + self.cls_loss(self.id_cls(img), pid) +  self.cls_loss(self.id_cls(cap), pid)\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += loss.item()\n",
    "\n",
    "            # log\n",
    "            if (i+1) % self.cfg.print_freq == 0:\n",
    "                print(\"ep-%d, bs-%d, [id-loss] %.6f\" % (epoch, i, cum_loss / self.cfg.print_freq))\n",
    "                cum_loss = 0.0\n",
    "                \n",
    "manager = Manager(cfg, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: ID Loss only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.melt_img_layer(num_layer_to_melt=1)\n",
    "param_to_optimize = build_graph_optimizer([manager.model, manager.id_cls])\n",
    "optimizer = optim.Adam(param_to_optimize, lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10)\n",
    "\n",
    "for epoch in range(10):\n",
    "    manager.train_epoch_id(train_loader, optimizer, epoch, \"train-stage-1\")\n",
    "    acc = evaluator.evaluate(manager.model)\n",
    "    logger.log('[euclidean][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (acc['top-1'], acc['top-5'], acc['top-10']))\n",
    "    acc = cos_evaluator.evaluate(manager.model)\n",
    "    logger.log('[cosine   ][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (acc['top-1'], acc['top-5'], acc['top-10']))\n",
    "    scheduler.step()\n",
    "    manager.save_ckpt(epoch, acc, 'stage_1_id_last.pt')\n",
    "manager.save_ckpt(epoch, acc, 'id_initialized.pt')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
