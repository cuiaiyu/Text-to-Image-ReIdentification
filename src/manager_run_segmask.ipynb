{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.wider_part_dataset import build_wider_dataloader\n",
    "from datasets.text_test_datasets import build_text_test_loader\n",
    "from datasets.image_test_datasets import build_image_test_loader\n",
    "from models.encoder import Model, MLP\n",
    "from evaluators.global_evaluator import GlobalEvaluator\n",
    "from evaluators.np_evaluator import NPEvaluator\n",
    "from loss.loss import crossmodal_triplet_loss, cos_distance, triplet_cos_loss\n",
    "from loggers.logger import Logger\n",
    "from manager import build_graph_optimizer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "from attentions.rga_attention import RGA_attend_one_to_many_batch, RGA_attend_one_to_many\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from configs.args import load_arg_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/aiyucui2/wider/checkpoints/reID/debug'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a9ac04d96d0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/aiyucui2/wider/checkpoints/reID/debug'"
     ]
    }
   ],
   "source": [
    "parser = load_arg_parser()\n",
    "cfg = parser.parse_args(\"\")\n",
    "cfg.data_root = \"/data/aiyucui2/wider\"\n",
    "root = cfg.data_root\n",
    "\n",
    "# data path\n",
    "cfg.anno_path = os.path.join(root, cfg.anno_path)\n",
    "cfg.img_dir = os.path.join(root, cfg.img_dir)\n",
    "cfg.val_anno_path = os.path.join(root, cfg.val_anno_path)\n",
    "cfg.val_img_dir = os.path.join(root, cfg.val_img_dir)\n",
    "cfg.gt_file_fn = os.path.join(root, cfg.gt_file_fn)\n",
    "\n",
    "# meta data path\n",
    "cfg.cheap_candidate_fn = os.path.join(root, cfg.cheap_candidate_fn)\n",
    "cfg.vocab_path = os.path.join(root, cfg.vocab_path)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# sys path\n",
    "cfg.model_path = os.path.join(root, cfg.model_path)\n",
    "cfg.output_path = os.path.join(root, cfg.output_path)\n",
    "ckpt_root = \"/shared/rsaas/aiyucui2/wider_person/checkpoints/reID/baseline\"\n",
    "load_exp_name = \"dist_fn_cosine_imgbb_resnet50_capbb_bigru_embed_size_1024_batch_96_lr_0.0001_captype_sent_img_meltlayer_2_cos_margin_0.2_np_False\"\n",
    "cfg.load_ckpt_fn = os.path.join(ckpt_root, load_exp_name, \"stage_1_id_last.pt\")\n",
    "cfg.debug = False\n",
    "cfg.embed_size = 1024\n",
    "cfg.batch_size = 96\n",
    "cfg.img_backbone_opt = \"resnet50\"\n",
    "cfg.num_gpus = 1\n",
    "cfg.cap_backbone_opt = \"bigru\"\n",
    "cfg.dim = (384,128)\n",
    "cfg.dist_fn_opt = \"cosine\"\n",
    "cfg.np = False\n",
    "cfg.img_num_cut = 6\n",
    "cfg.img_num_cut = 1 if not cfg.np else cfg.img_num_cut\n",
    "cfg.np_token_length = 5\n",
    "cfg.sent_token_length =30\n",
    "\n",
    "cfg.cap_embed_type='sent'\n",
    "# exp_name\n",
    "cfg.exp_name = 'debug'\n",
    "cfg.model_path = os.path.join(\"/shared/rsaas/aiyucui2/wider_person\", cfg.model_path, cfg.exp_name)\n",
    "cfg.output_path = os.path.join(\"/shared/rsaas/aiyucui2/wider_person\", cfg.output_path, cfg.exp_name)\n",
    "\n",
    "if not os.path.exists(cfg.model_path):\n",
    "    os.mkdir(cfg.model_path)\n",
    "if not os.path.exists(cfg.output_path):\n",
    "    os.mkdir(cfg.output_path)\n",
    "# logger\n",
    "logger = Logger(\"test_sent30.txt\") #os.path.join(cfg.output_path, cfg.exp_name+\".txt\"))\n",
    "print(cfg.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loader\n",
    "train_loader = build_wider_dataloader(cfg)\n",
    "# test loader (loading image and text separately)\n",
    "test_text_loader = build_text_test_loader(cfg) \n",
    "test_image_loader = build_image_test_loader(cfg) \n",
    "\n",
    "# Evaluator\n",
    "Evaluator = NPEvaluator if cfg.np else GlobalEvaluator\n",
    "\n",
    "evaluator = Evaluator(img_loader=test_image_loader, \n",
    "                          cap_loader=test_text_loader, \n",
    "                          gt_file_path=cfg.gt_file_fn,\n",
    "                          embed_size=cfg.embed_size,\n",
    "                          logger=logger,\n",
    "                          dist_fn_opt=\"euclidean\")\n",
    "cos_evaluator = Evaluator(img_loader=test_image_loader, \n",
    "                          cap_loader=test_text_loader, \n",
    "                          gt_file_path=cfg.gt_file_fn,\n",
    "                          embed_size=cfg.embed_size,\n",
    "                          logger=logger,\n",
    "                          dist_fn_opt=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt_path = \"/shared/rsaas/aiyucui2/wider_person/checkpoints/reID/resnet18_bigru_512/resnet18_bigru_512_id_initalized.pt\"\n",
    "#ckpt = torch.load(ckpt_path)\n",
    "cfg.num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     60,
     66,
     74,
     112,
     127,
     144,
     152,
     158,
     244
    ]
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import os\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from models.encoder import Model, MLP\n",
    "from loss.loss import triplet_cos_loss, crossmodal_triplet_loss, triplet_cos_loss_inner\n",
    "\n",
    "from attentions.rga_attention import RGA_attend_one_to_many_batch, RGA_attend_one_to_many\n",
    "from models.texts.gru_backbone import BiGRUBackbone as CaptionBackbone\n",
    "  \n",
    "def triplet_cos_loss(imgs, caps, pids):\n",
    "    loss = 0.0\n",
    "    N = imgs.size(0)\n",
    "    for i, pid in enumerate(pids):\n",
    "        neg_imgs = imgs[pids != pid]\n",
    "        neg_caps = imgs[pids != pid]\n",
    "        pos_imgs = imgs[i:i+1].expand_as(neg_imgs)\n",
    "        pos_caps = caps[i:i+1].expand_as(neg_caps)\n",
    "        cap_tri_loss = triplet_cos_loss_inner(pos_imgs, pos_caps, neg_caps)\n",
    "        img_tri_loss = triplet_cos_loss_inner(pos_caps, pos_imgs, neg_imgs)\n",
    "        loss = loss + cap_tri_loss + img_tri_loss\n",
    "    return loss / N\n",
    "\n",
    "def triplet_cos_loss_attention(fulls, parts, pids):\n",
    "    loss = 0.0\n",
    "    N = fulls.size(0)\n",
    "    \n",
    "    for i, pid in enumerate(pids):\n",
    "        curr_part = parts[i:i+1]\n",
    "        curr_full = fulls[i:i+1]\n",
    "        pos_part = RGA_attend_one_to_many_batch(curr_full, curr_part, 'cosine')\n",
    "        \n",
    "        neg_fulls = fulls[pids != pid]\n",
    "        M, K = neg_fulls.size()\n",
    "        neg_fulls = neg_fulls[:,None,:].expand(M, parts.size(1), K)\n",
    "        neg_parts = RGA_attend_one_to_many_batch(neg_fulls, curr_part.expand_as(neg_fulls), 'cosine')\n",
    "        \n",
    "        loss = loss + triplet_cos_loss_inner(curr_full.expand_as(neg_parts), \n",
    "                                             pos_part.expand_as(neg_parts), \n",
    "                                             neg_parts)\n",
    "    return loss / N\n",
    "        \n",
    "def regional_alignment_text(fulls, parts, p2fs, dist_fn_opt):\n",
    "    start_index = 0\n",
    "    aligned = []\n",
    "    for i, jump in enumerate(p2fs):\n",
    "        curr_parts = parts[start_index:start_index + jump]\n",
    "        start_index += jump\n",
    "        curr_full = fulls[i:i+1]\n",
    "        aligned.append(RGA_attend_one_to_many(curr_full, curr_parts, dist_fn_opt))\n",
    "    return torch.cat(aligned)\n",
    "\n",
    "def regional_alignment_image(fulls, parts, dist_fn_opt):\n",
    "    return RGA_attend_one_to_many_batch(fulls, parts, dist_fn_opt)\n",
    "  \n",
    "    \n",
    "class Manager:\n",
    "    def __init__(self, args, logger):\n",
    "        self.log = logger.log\n",
    "        self.cfg = args\n",
    "        self._init_models()\n",
    "        self._init_criterion()\n",
    "    \n",
    "    def _init_criterion(self):\n",
    "        if self.cfg.dist_fn_opt == \"cosine\":\n",
    "            self.triplet_loss = triplet_cos_loss\n",
    "        elif self.cfg.dist_fn_opt == \"euclidean\":\n",
    "            self.triplet_loss = nn.TripletMarginLoss()\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.log(\"[Trainer][init] criterion initialized.\")\n",
    "\n",
    "    def _init_models(self):\n",
    "        # encoder\n",
    "        self.model = Model(embed_size=self.cfg.embed_size, \n",
    "                          image_opt=self.cfg.img_backbone_opt, \n",
    "                          caption_opt=self.cfg.cap_backbone_opt,\n",
    "                          cap_embed_type=self.cfg.cap_embed_type,\n",
    "                          img_num_cut=self.cfg.img_num_cut,\n",
    "                          regional_embed_size=self.cfg.regional_embed_size).cuda()\n",
    "        # id classifer\n",
    "        self.id_cls = nn.Linear(self.cfg.embed_size, self.cfg.num_ids).cuda()\n",
    "        # RGA image mlp\n",
    "        self.rga_img_mlp = MLP(self.cfg.regional_embed_size, self.cfg.embed_size).cuda()\n",
    "        # RGA text mlp\n",
    "        self.rga_cap_mlp = MLP(self.cfg.embed_size, self.cfg.embed_size).cuda()\n",
    "        # np encoder\n",
    "        self.np_encoder = CaptionBackbone(embed_size=self.cfg.embed_size, \n",
    "                                          caption_opt=self.cfg.cap_backbone_opt,\n",
    "                                          cap_embed_type=self.cfg.cap_embed_type).cuda()\n",
    "        # gpu\n",
    "        self.all_models = {\n",
    "            \"model\": self.model,\n",
    "            \"id_cls\": self.id_cls, \n",
    "            \"rga_img_mlp\": self.rga_img_mlp,\n",
    "            \"rga_cap_mlp\": self.rga_cap_mlp,\n",
    "            'np_encoder': self.np_encoder,\n",
    "        }\n",
    "        print(self.cfg.num_gpus)\n",
    "        if self.cfg.num_gpus > 1:\n",
    "            print('here')\n",
    "            for name in self.all_models.keys():\n",
    "                print('data parallel')\n",
    "                self.all_models[name] = nn.DataParallel(self.all_models[name])\n",
    "        # load ckpt\n",
    "        self.reset_ckpt()\n",
    "        \n",
    "        \n",
    "        self.log(\"[Trainer][init] model initialized.\")\n",
    "\n",
    "    def reset_ckpt(self):\n",
    "        self.start_epoch = 0\n",
    "        self.acc_history = []\n",
    "        self.best_acc = ({'top-1':0, 'top-1': 0, 'top-1': 0}, self.start_epoch)\n",
    "        if self.cfg.load_ckpt_fn == \"0\":\n",
    "            self.log(\"[Trainer][init] initialize fresh model.\")\n",
    "            return\n",
    "        ckpt = torch.load(self.cfg.load_ckpt_fn)\n",
    "        self.start_epoch = ckpt[\"epoch\"] + 1\n",
    "        self.acc_history = ckpt[\"acc_history\"]\n",
    "        for name, network in self.all_models.items():\n",
    "            if name in ckpt:\n",
    "                network.load_state_dict(ckpt[name], strict=False)\n",
    "                self.log(\"[Trainer][init] load pre-trained %s from %s.\" % (name, self.cfg.load_ckpt_fn))\n",
    "              \n",
    "    def save_ckpt(self, epoch, acc, fn):\n",
    "        # update acc history \n",
    "        self.acc_history.append((acc, epoch))\n",
    "        if acc['top-1'] > self.best_acc[0]['top-1']:\n",
    "            self.best_acc = (acc, epoch)\n",
    "        # ckpt \n",
    "        ckpt = {\n",
    "            \"epoch\": epoch,\n",
    "            \"acc_history\": self.acc_history,\n",
    "            \"best_acc\": self.best_acc,\n",
    "            }\n",
    "        for name, network in self.all_models.items():\n",
    "            ckpt[name] = network.module.state_dict() if isinstance(network, nn.DataParallel) else network.state_dict()\n",
    "\n",
    "        path = os.path.join(self.cfg.model_path, fn)\n",
    "        torch.save(ckpt, path)\n",
    "            \n",
    "    def todevice(self, batch):\n",
    "        ret = []\n",
    "        for arg in batch:\n",
    "            if isinstance(arg, torch.Tensor):\n",
    "                arg = arg.cuda()\n",
    "            ret.append(arg)\n",
    "        return tuple(ret)\n",
    "    \n",
    "    def melt_img_layer(self, num_layer_to_melt=1):\n",
    "        if isinstance(self.model, nn.DataParallel):\n",
    "            self.model.module.img_backbone.melt_layer(8 - num_layer_to_melt)\n",
    "        else:\n",
    "            self.model.img_backbone.melt_layer(8 - num_layer_to_melt)\n",
    "     \n",
    "    def train_epoch_global(self, train_data, optimizer, epoch, note=\"train\"):\n",
    "        self.model.train()\n",
    "        cum_tri_loss, cum_id_loss = 0.0, 0.0\n",
    "        for i, data in tqdm(enumerate(train_data), \"%s, epoch%d\" % (note, epoch)):\n",
    "            # load data\n",
    "            data = self.todevice(data)\n",
    "            img, cap, pid = data\n",
    "            \n",
    "            # encode\n",
    "            #img, pos_img, neg_img = self.model(img), self.model(pos_img), self.model(neg_img)\n",
    "            #cap, pos_cap, neg_cap = self.model(cap), self.model(pos_cap), self.model(neg_cap)\n",
    "            img, cap = self.model(img), self.model(cap)\n",
    "\n",
    "\n",
    "            # loss\n",
    "            tri_loss = triplet_cos_loss(img, cap, pid)\n",
    "            id_loss = self.cls_loss(self.id_cls(img), pid) + self.cls_loss(self.id_cls(cap), pid)\n",
    "            loss = tri_loss + id_loss\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            # log\n",
    "            cum_tri_loss += tri_loss.item()\n",
    "            cum_id_loss += id_loss.item()\n",
    "            if (i+1) % self.cfg.print_freq == 0:\n",
    "                out_string = \"[ep-%d, bs-%d] \" % (epoch, i)\n",
    "                out_string += \"[tri-loss] %.6f, \" % (cum_tri_loss / self.cfg.print_freq)\n",
    "                out_string += \"[id-loss] %.6f, \" % (cum_id_loss / self.cfg.print_freq)\n",
    "                self.log(out_string)\n",
    "                cum_tri_loss, cum_id_loss = 0.0, 0.0\n",
    "                \n",
    "    def train_epoch_regional(self, train_data, optimizer, epoch, note=\"train\"):\n",
    "        self.model.train(); self.rga_img_mlp.train(); self.rga_cap_mlp.train(); self.np_encoder.train()\n",
    "\n",
    "        cum_tri_loss, cum_tri_image_regional_loss, cum_tri_text_regional_loss, cum_id_loss = 0.0, 0.0, 0.0, 0.0\n",
    "        for i, data in tqdm(enumerate(train_data), \"%s, epoch%d\" % (note,epoch)):\n",
    "            # load data\n",
    "            data = self.todevice(data)\n",
    "            (img, cap, nps, n2c, pid) = data\n",
    "            # import pdb;pdb.set_trace()\n",
    "\n",
    "\n",
    "            img, img_part = self.model(img)\n",
    "            cap = self.model(cap)\n",
    "            \n",
    "            N, M, T = nps.size()\n",
    "            #nps = self.rga_cap_mlp(self.np_encoder(nps))\n",
    "            nps = self.rga_cap_mlp(self.model(nps.view(-1, T))).view(N, M, -1)\n",
    "            \n",
    "            # part\n",
    "            img_part = self.rga_img_mlp(img_part)\n",
    "\n",
    "            img_part = RGA_attend_one_to_many_batch(cap, img_part, self.cfg.dist_fn_opt)\n",
    "            #cap_part = regional_alignment_text(img, nps, n2c, self.cfg.dist_fn_opt)\n",
    "            cap_part = RGA_attend_one_to_many_batch(img, nps, self.cfg.dist_fn_opt)\n",
    "\n",
    "            # loss\n",
    "            tri_loss =  self.triplet_loss(img, cap, pid) \n",
    "            tri_text_regional_loss =  self.triplet_loss(img, cap_part, pid) \n",
    "            tri_image_regional_loss = self.triplet_loss(cap, img_part, pid) \n",
    "            id_loss = self.cls_loss(self.id_cls(img), pid) +  self.cls_loss(self.id_cls(cap), pid)\n",
    "            id_loss = id_loss + self.cls_loss(self.id_cls(img_part), pid) +  self.cls_loss(self.id_cls(cap_part), pid)\n",
    "\n",
    "\n",
    "            loss = tri_loss + tri_image_regional_loss  + tri_text_regional_loss + id_loss\n",
    "\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # log\n",
    "            cum_tri_loss += tri_loss.item()\n",
    "            cum_tri_image_regional_loss += tri_image_regional_loss.item()\n",
    "            cum_tri_text_regional_loss += tri_text_regional_loss.item()\n",
    "            cum_id_loss += id_loss.item()\n",
    "            \n",
    "            if (i+1) % self.cfg.print_freq == 0:\n",
    "                out_string = \"[ep-%d, bs-%d] \" % (epoch, i)\n",
    "                out_string += \"[id-loss] %.6f, \" % (cum_id_loss / self.cfg.print_freq)\n",
    "                out_string += \"[tri-loss] %.6f, \" % (cum_tri_loss / self.cfg.print_freq)\n",
    "                out_string += \"[img_rga] %.6f, \" %  (cum_tri_image_regional_loss / self.cfg.print_freq)\n",
    "                out_string += \"[cap_rga] %.6f \" % (cum_tri_text_regional_loss / self.cfg.print_freq)\n",
    "                self.log(out_string)\n",
    "                cum_tri_loss, cum_tri_image_regional_loss, cum_tri_text_regional_loss, cum_id_loss = 0.0, 0.0, 0.0, 0.0       \n",
    "    def train_epoch_id(self, train_data, optimizer, epoch, note=\"train\"):\n",
    "        self.model.train()\n",
    "        self.id_cls.train()\n",
    "        cum_loss = 0.0\n",
    "        for i, data in tqdm(enumerate(train_data), \"%s, epoch%d\" % (note,epoch)):\n",
    "            # load data\n",
    "            data = self.todevice(data)\n",
    "            (img, cap, pid) = data\n",
    "            img = self.model(img)\n",
    "            cap = self.model(cap)\n",
    "\n",
    "            # loss\n",
    "            loss = 0.0\n",
    "            loss = loss + self.cls_loss(self.id_cls(img), pid) +  self.cls_loss(self.id_cls(cap), pid)\n",
    "            cum_loss += loss.item()\n",
    "            \n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            # log\n",
    "            if (i+1) % self.cfg.print_freq == 0:\n",
    "                self.log(\"ep-%d, bs-%d, [id-loss] %.6f\" % (epoch, i, cum_loss / self.cfg.print_freq))\n",
    "                cum_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cfg.num_ids = len(train_loader.dataset.person2label.values())\n",
    "manager = Manager(cfg, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    if cfg.np:\n",
    "        acc = cos_evaluator.evaluate(manager.model, manager.rga_img_mlp, manager.rga_cap_mlp)\n",
    "    else:\n",
    "        acc = cos_evaluator.evaluate(manager.model)\n",
    "    logger.log('[cosine   ][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (acc['top-1'], acc['top-5'], acc['top-10']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: ID Loss only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    logger.log(\"======== [Stage 1] ============\")\n",
    "    manager.melt_img_layer(num_layer_to_melt=1)\n",
    "    param_to_optimize = build_graph_optimizer([manager.model, manager.id_cls])\n",
    "    optimizer = optim.Adam(param_to_optimize, lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10)\n",
    "    \n",
    "    for epoch in range(0):\n",
    "        manager.train_epoch_id(train_loader, optimizer, epoch, \"train-stage-1\")\n",
    "        acc = evaluator.evaluate(manager.model)\n",
    "        logger.log('[euclidean][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (acc['top-1'], acc['top-5'], acc['top-10']))\n",
    "        acc = cos_evaluator.evaluate(manager.model)\n",
    "        logger.log('[cosine   ][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (acc['top-1'], acc['top-5'], acc['top-10']))\n",
    "        scheduler.step()\n",
    "        manager.save_ckpt(epoch, acc, 'stage_1_id_last.pt')\n",
    "    manager.save_ckpt(epoch, acc, 'id_initialized.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Matching + ID Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "manager.melt_img_layer(num_layer_to_melt=2)\n",
    "param_to_optimize = build_graph_optimizer([manager.model, manager.id_cls])\n",
    "optimizer = optim.Adam(param_to_optimize, lr=2e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10)\n",
    "train_epoch = manager.train_epoch_regional if cfg.np else manager.train_epoch_global\n",
    "for epoch in range(15):\n",
    "    train_epoch(train_loader, optimizer, epoch, \"train-stage-2\")\n",
    "    if cfg.np:\n",
    "        cos_acc = cos_evaluator.evaluate(manager.model, manager.rga_img_mlp, manager.rga_cap_mlp)\n",
    "    else:\n",
    "        cos_acc = cos_evaluator.evaluate(manager.model)\n",
    "    logger.log('[cosine   ][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (cos_acc['top-1'], cos_acc['top-5'], cos_acc['top-10']))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.save_ckpt(epoch, acc, \"match_stage2_trained.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.np:\n",
    "    cos_acc = cos_evaluator.evaluate(manager.model, manager.rga_img_mlp, manager.rga_cap_mlp)\n",
    "else:\n",
    "    cos_acc = cos_evaluator.evaluate(manager.model)\n",
    "logger.log('[cosine   ][global] R@1: %.4f | R@5: %.4f | R@10: %.4f' % (cos_acc['top-1'], cos_acc['top-5'], cos_acc['top-10']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
